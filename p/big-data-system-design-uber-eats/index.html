<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="How to Design the Data Infra for Uber Eats Order Tracking Page Intro A real world example to build scalable data analytics with tools like Kafka, Flink, Spark, Presto, Airflow, Iceberg, etc. Let&rsquo;s delve into a more technical scenario that incorporates Kafka, Flink, Spark, Hadoop, Iceberg, Airflow, and Presto into a comprehensive real-time data processing and analytics pipeline: Assumptions for the Technical Workflow: An Uber Eats-like app tracks the location of drivers and communicates order details to users."><title>Big Data System Design Uber Eats</title>
<link rel=canonical href=https://blog.xiax.xyz/p/big-data-system-design-uber-eats/><link rel=stylesheet href=/scss/style.min.3eb3ec85c4678737b7eff912dd406e23d3999d96facbe09744dc8f1364656d34.css><meta property='og:title' content="Big Data System Design Uber Eats"><meta property='og:description' content="How to Design the Data Infra for Uber Eats Order Tracking Page Intro A real world example to build scalable data analytics with tools like Kafka, Flink, Spark, Presto, Airflow, Iceberg, etc. Let&rsquo;s delve into a more technical scenario that incorporates Kafka, Flink, Spark, Hadoop, Iceberg, Airflow, and Presto into a comprehensive real-time data processing and analytics pipeline: Assumptions for the Technical Workflow: An Uber Eats-like app tracks the location of drivers and communicates order details to users."><meta property='og:url' content='https://blog.xiax.xyz/p/big-data-system-design-uber-eats/'><meta property='og:site_name' content='A Cat Entertainer'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='ubereats'><meta property='article:tag' content='big data'><meta property='article:tag' content='technical interview'><meta property='article:tag' content='system design'><meta property='article:tag' content='kafka'><meta property='article:tag' content='flink'><meta property='article:tag' content='iceberg'><meta property='article:tag' content='hadoop'><meta property='article:tag' content='presto'><meta property='article:tag' content='airflow'><meta property='article:published_time' content='2024-03-25T05:40:03-07:00'><meta property='article:modified_time' content='2024-03-25T05:40:03-07:00'><meta property='og:image' content='https://blog.xiax.xyz/p/big-data-system-design-uber-eats/Uber_Eats_Logo.jpg'><meta name=twitter:title content="Big Data System Design Uber Eats"><meta name=twitter:description content="How to Design the Data Infra for Uber Eats Order Tracking Page Intro A real world example to build scalable data analytics with tools like Kafka, Flink, Spark, Presto, Airflow, Iceberg, etc. Let&rsquo;s delve into a more technical scenario that incorporates Kafka, Flink, Spark, Hadoop, Iceberg, Airflow, and Presto into a comprehensive real-time data processing and analytics pipeline: Assumptions for the Technical Workflow: An Uber Eats-like app tracks the location of drivers and communicates order details to users."><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://blog.xiax.xyz/p/big-data-system-design-uber-eats/Uber_Eats_Logo.jpg'><link rel="shortcut icon" href=/favicon.png><script async src="https://www.googletagmanager.com/gtag/js?id=G-DBH469RMWM"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-DBH469RMWM",{anonymize_ip:!1})}</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu24609b204ce41225aec778067808461c_22211_300x0_resize_q75_box.jpeg width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>ğŸ±</span></figure><div class=site-meta><h1 class=site-name><a href=/>A Cat Entertainer</a></h1><h2 class=site-description>Engineer | Cat Entertainer | Photographer | Gamer</h2></div></header><ol class=social-menu><li><a href target=_blank rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg></a></li><li><a href=https://github.com/xingfanxia target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://lightroom.adobe.com/u/xingfanxia target=_blank title=lightroom rel=me><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-camera"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 7h1a2 2 0 002-2 1 1 0 011-1h6a1 1 0 011 1 2 2 0 002 2h1a2 2 0 012 2v9a2 2 0 01-2 2H5a2 2 0 01-2-2V9a2 2 0 012-2"/><path d="M9 13a3 3 0 106 0 3 3 0 00-6 0"/></svg></a></li><li><a href=https://www.linkedin.com/in/xingfanxia/ target=_blank title=linkedin rel=me><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-brand-linkedin"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4m0 2a2 2 0 012-2h12a2 2 0 012 2v12a2 2 0 01-2 2H6a2 2 0 01-2-2z"/><path d="M8 11v5"/><path d="M8 8v.01"/><path d="M12 16v-5"/><path d="M16 16v-3a2 2 0 00-4 0"/></svg></a></li><li><a href=https://xiax.xyz target=_blank title=mysite rel=me><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-palette"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 21a9 9 0 010-18c4.97.0 9 3.582 9 8 0 1.06-.474 2.078-1.318 2.828S17.693 15 16.5 15H14a2 2 0 00-1 3.75A1.3 1.3.0 0112 21"/><path d="M8.5 10.5m-1 0a1 1 0 102 0 1 1 0 10-2 0"/><path d="M12.5 7.5m-1 0a1 1 0 102 0 1 1 0 10-2 0"/><path d="M16.5 10.5m-1 0a1 1 0 102 0 1 1 0 10-2 0"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/links/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li><a href=/apps><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-box"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 3l8 4.5v9L12 21l-8-4.5v-9L12 3"/><path d="M12 12l8-4.5"/><path d="M12 12v9"/><path d="M12 12 4 7.5"/></svg>
<span>Apps</span></a></li><li><a href=/projects><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-code"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M7 8l-4 4 4 4"/><path d="M17 8l4 4-4 4"/><path d="M14 4l-4 16"/></svg>
<span>Projects</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#assumptions-for-the-technical-workflow>Assumptions for the Technical Workflow:</a></li><li><a href=#overall-architecture-design>Overall Architecture Design</a><ol><li><a href=#simple-architecture-diagram>Simple Architecture Diagram</a><ol><li><a href=#ascii-style>Ascii Style</a></li><li><a href=#mermaid-style>Mermaid Style</a></li></ol></li><li><a href=#technical-workflow>Technical Workflow:</a></li><li><a href=#1-data-ingestion-apache-kafka>1. Data Ingestion (Apache Kafka):</a></li><li><a href=#2-real-time-stream-processing-apache-flink>2. Real-time Stream Processing (Apache Flink):</a></li><li><a href=#3-batch-processing-and-analysis-apache-spark>3. Batch Processing and Analysis (Apache Spark):</a></li><li><a href=#4-workflow-orchestration-apache-airflow>4. Workflow Orchestration (Apache Airflow):</a></li><li><a href=#5-data-storage-hadoop--apache-iceberg>5. Data Storage (Hadoop + Apache Iceberg):</a></li><li><a href=#6-interactive-querying-presto>6. Interactive Querying (Presto):</a></li><li><a href=#7-data-lifecycle-and-schema-management>7. Data Lifecycle and Schema Management:</a></li><li><a href=#8-advanced-machine-learning-and-analytics-spark--mllib>8. Advanced Machine Learning and Analytics (Spark + MLlib):</a></li><li><a href=#9-monitoring-and-governance>9. Monitoring and Governance:</a></li></ol></li><li><a href=#technical-detail-followups>Technical Detail Followups</a><ol><li><a href=#kafka>Kafka</a></li><li><a href=#flink>Flink</a></li><li><a href=#spark>Spark</a></li><li><a href=#hadoop>Hadoop</a></li><li><a href=#iceberg>Iceberg</a></li><li><a href=#airflow>Airflow</a></li><li><a href=#presto>Presto</a></li></ol></li><li><a href=#design-choice-follow-ups>Design Choice Follow ups</a><ol><li><a href=#kafka-1>Kafka</a></li><li><a href=#flink-1>Flink</a></li><li><a href=#spark-1>Spark</a></li><li><a href=#hadoop-hdfs>Hadoop (HDFS)</a></li><li><a href=#iceberg-1>Iceberg</a></li><li><a href=#airflow-1>Airflow</a></li><li><a href=#presto-1>Presto</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/big-data-system-design-uber-eats/><img src=/p/big-data-system-design-uber-eats/Uber_Eats_Logo_hu9919f7b3f46635b6673d32d5992520f9_38864_800x0_resize_q75_box.jpg srcset="/p/big-data-system-design-uber-eats/Uber_Eats_Logo_hu9919f7b3f46635b6673d32d5992520f9_38864_800x0_resize_q75_box.jpg 800w, /p/big-data-system-design-uber-eats/Uber_Eats_Logo_hu9919f7b3f46635b6673d32d5992520f9_38864_1600x0_resize_q75_box.jpg 1600w" width=800 height=400 loading=lazy alt="Featured image of post Big Data System Design Uber Eats"></a></div><div class=article-details><header class=article-category><a href=/categories/technical-interview/>Technical Interview
</a><a href=/categories/system-design/>System Design
</a><a href=/categories/big-data/>Big Data</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/big-data-system-design-uber-eats/>Big Data System Design Uber Eats</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Mar 25, 2024</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>13 minute read</time></div></footer></div></header><section class=article-content><h1 id=how-to-design-the-data-infra-for-uber-eats-order-tracking-page>How to Design the Data Infra for Uber Eats Order Tracking Page</h1><h1 id=intro>Intro</h1><p>A real world example to build scalable data analytics with tools like Kafka, Flink, Spark, Presto, Airflow, Iceberg, etc. Let&rsquo;s delve into a more technical scenario that incorporates Kafka, Flink, Spark, Hadoop, Iceberg, Airflow, and Presto into a comprehensive real-time data processing and analytics pipeline:</p><h2 id=assumptions-for-the-technical-workflow>Assumptions for the Technical Workflow:</h2><ul><li>An Uber Eats-like app tracks the location of drivers and communicates order details to users.</li><li>The system must handle real-time processing, such as matching drivers with orders, and longer-term analytical processing, like optimizing driver routes and forecasting delivery times.</li></ul><h2 id=overall-architecture-design>Overall Architecture Design</h2><h3 id=simple-architecture-diagram>Simple Architecture Diagram</h3><h4 id=ascii-style>Ascii Style</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>Driver</span> <span class=n>Apps</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span> <span class=n>Publish</span> <span class=n>GPS</span> <span class=n>locations</span>
</span></span><span class=line><span class=cl>     <span class=n>v</span>
</span></span><span class=line><span class=cl>    <span class=n>Kafka</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span>\
</span></span><span class=line><span class=cl>     <span class=o>|</span> <span class=o>|</span> <span class=n>Driver</span> <span class=n>locations</span> <span class=n>stream</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span> <span class=o>|</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span> <span class=n>v</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span> <span class=n>Flink</span> <span class=o>----------&gt;</span> <span class=n>Compute</span> <span class=n>aggregations</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span> <span class=o>|</span>               <span class=o>|</span> <span class=n>Join</span> <span class=n>streams</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span> <span class=o>|</span> <span class=n>Order</span> <span class=n>events</span>  <span class=o>|</span> <span class=n>Manage</span> <span class=n>stateful</span> <span class=n>processing</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span> <span class=o>|</span> <span class=n>Stream</span>        <span class=o>|</span>
</span></span><span class=line><span class=cl>     <span class=n>v</span> <span class=o>|</span>               <span class=o>|</span>
</span></span><span class=line><span class=cl><span class=n>Order</span> <span class=n>System</span> <span class=o>&amp;</span> <span class=n>User</span> <span class=n>Apps</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span>               <span class=o>|</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span> <span class=n>Write</span> <span class=n>Flink</span> <span class=n>results</span>
</span></span><span class=line><span class=cl>     <span class=n>v</span>               <span class=o>|</span>
</span></span><span class=line><span class=cl>    <span class=n>Hadoop</span> <span class=o>&lt;--------/</span>   <span class=o>&lt;--------------</span> <span class=n>Airflow</span> <span class=n>orchestrating</span> <span class=n>tasks</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span>   <span class=o>^</span>                            <span class=o>|</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span>   <span class=o>|</span> <span class=n>Data</span> <span class=n>written</span> <span class=n>back</span> <span class=n>by</span> <span class=n>Spark</span> <span class=o>|</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span>   <span class=o>|</span> <span class=ow>and</span> <span class=n>other</span> <span class=n>batch</span> <span class=n>jobs</span>       <span class=o>|</span>
</span></span><span class=line><span class=cl>     <span class=n>v</span>   <span class=o>|</span>                            <span class=o>|</span>
</span></span><span class=line><span class=cl> <span class=n>Iceberg</span> <span class=n>Tables</span> <span class=o>&lt;---------------------+</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span> <span class=n>SQL</span> <span class=n>queries</span> <span class=k>for</span> <span class=n>analytics</span>
</span></span><span class=line><span class=cl>     <span class=n>v</span>
</span></span><span class=line><span class=cl>   <span class=n>Presto</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span>
</span></span><span class=line><span class=cl>     <span class=o>|</span> <span class=n>Visualization</span> <span class=o>&amp;</span> <span class=n>Reporting</span>
</span></span><span class=line><span class=cl>     <span class=n>v</span>
</span></span><span class=line><span class=cl><span class=n>Business</span> <span class=n>Apps</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=mermaid-style>Mermaid Style</h4><pre class=mermaid>graph TB
    DA[Driver Apps] -->|Publish GPS locations| K[Kafka]
    K -->|Driver locations stream| F[Flink]
    K -->|Order events stream| F
    F -->|Real-time processing| OA[Order System & User Apps]
    F -->|Write Flink results| H[Hadoop]
    
    SP[Spark for Batch Analysis] -->|Write batch results| H
    A[Airflow] -->|Schedule & orchestrate| SP
    
    H -->|Data management| I[Iceberg Tables]
    
    P[Presto] -->|SQL queries| I
    
    B[Business Apps] -->|Visualization & Reporting| P
    
    %% Define styling
    classDef default fontsize:16px, color:#fff, fill:#000, stroke:#fff, stroke-width:2px;
    linkStyle default stroke:white,stroke-width:1px;
</pre><h3 id=technical-workflow>Technical Workflow:</h3><h3 id=1-data-ingestion-apache-kafka>1. Data Ingestion (Apache Kafka):</h3><ul><li><strong>Kafka Producers</strong>: The driver app constantly publishes GPS coordinates to a Kafka topic <code>driver-locations</code>, using a producer client library. Each message might be keyed by driver ID to ensure location updates for a given driver go to the same partition for order.</li><li><strong>Kafka Consumers</strong>: Other systems subscribe to the <code>driver-locations</code> topic to receive updates. Additionally, consumer applications are set up for topics like <code>order-events</code> that handle order placement, acceptance, and completions.</li><li>Kafka topics are partitioned and replicated to ensure scalability and fault tolerance.</li></ul><h3 id=2-real-time-stream-processing-apache-flink>2. Real-time Stream Processing (Apache Flink):</h3><ul><li><strong>Flink Jobs</strong>: Flink jobs are configured to subscribe to <code>driver-locations</code> and <code>order-events</code>. They perform tasks such as:<ul><li>Windowed aggregations to compute the latest location of each driver.</li><li>Join operations between driver locations and pending orders to facilitate real-time matching and dispatching.</li><li>Stateful processing for ETA calculations and sending notifications to customers via external systems when a driver is nearby.</li></ul></li></ul><h3 id=3-batch-processing-and-analysis-apache-spark>3. Batch Processing and Analysis (Apache Spark):</h3><ul><li><strong>Spark Jobs</strong>: Scheduled batch Spark jobs are written in Scala or Python and deal with complex analytical tasks, including:<ul><li>Training machine learning models on historical delivery data to predict delivery times (using MLlib).</li><li>Aggregating delivery data nightly to create performance metrics per driver or per region.</li></ul></li></ul><h3 id=4-workflow-orchestration-apache-airflow>4. Workflow Orchestration (Apache Airflow):</h3><ul><li><strong>Airflow DAGs (Directed Acyclic Graphs)</strong>: Define the dependent jobs and workflows that orchestrate processing tasks. An Airflow DAG might include:<ul><li>A task to run a Spark job that rebuilds machine learning models.</li><li>Another task to batch-process the day&rsquo;s data and update Iceberg tables.</li><li>Scheduling and triggering Flink jobs for real-time streaming when needed.</li></ul></li></ul><h3 id=5-data-storage-hadoop--apache-iceberg>5. Data Storage (Hadoop + Apache Iceberg):</h3><ul><li><strong>HDFS</strong>: Raw data from Kafka is landed into HDFS, and processed data is stored there for long-term historical analysis.</li><li><strong>Iceberg Tables</strong>: Transactional data tables managed by Iceberg provide consistent snapshots of large-scale datasets and support schema evolution for the raw Kafka data and the results of Spark jobs.</li></ul><h3 id=6-interactive-querying-presto>6. Interactive Querying (Presto):</h3><ul><li><strong>Presto SQL Queries</strong>: Analysts use Presto to perform SQL queries on stored Hadoop data and Iceberg tables to gain insights or create real-time dashboards. Example queries might include:<ul><li>SQL to join today&rsquo;s real-time data with historical trends.</li><li>Aggregation queries to analyze delivery efficiency across different areas.</li></ul></li></ul><h3 id=7-data-lifecycle-and-schema-management>7. Data Lifecycle and Schema Management:</h3><ul><li>Iceberg table partitioning is configured for efficient data retrieval, e.g., by time window or geographical region.</li><li>Data retention policies are configured in Kafka to govern how long data is kept, considering storage costs and compliance requirements.</li><li>Iceberg&rsquo;s schema evolution allows for seamless transitions when altering data structures or incorporating new data sources.</li></ul><h3 id=8-advanced-machine-learning-and-analytics-spark--mllib>8. Advanced Machine Learning and Analytics (Spark + MLlib):</h3><ul><li>Historical data in Iceberg tables is used to train and refine predictive models for delivery ETA, taking advantage of features like lookback windows and seasonal trends.</li><li>Airflow DAGs keep model training and evaluations consistent, reproducible, and on schedule.</li></ul><h3 id=9-monitoring-and-governance>9. Monitoring and Governance:</h3><ul><li>Comprehensive logging is set up for all components, including Kafka brokers, Flink job managers, and Spark driver/executor processes.</li><li>A monitoring solution (such as Prometheus with Grafana) watches over the health and performance of the infrastructure, ensuring SLAs are met.</li><li>Data governance is enforced via policies and access controls for sensitive data in HDFS and Iceberg, audited by tools such as Apache Ranger.</li></ul><p>The synergy in such a technical workflow allows an Uber Eats-like service to leverage strengths from each tool â€” Kafka for ingestion, Flink for real-time processing, Spark for batch processing and ML, Airflow for orchestration, Iceberg for managing large-scale data tables, and Presto for interactive querying. This enables real-time communication to users and drivers while also providing a platform for advanced analytics and strategic decision-making based on historical and current data.</p><h2 id=technical-detail-followups>Technical Detail Followups</h2><h3 id=kafka>Kafka</h3><ul><li><p><strong>Q:</strong> How do you ensure data consistency in your Kafka cluster?</p><ul><li><strong>A:</strong> Kafka ensures data consistency by replicable partitions, where each partition has one leader and multiple in-sync replicas (ISRs). The leader handles all the read and write requests for that partition, and ISRs replicate the leader&rsquo;s data. Consumers typically read from the leader to ensure they receive the most up-to-date records.</li></ul></li><li><p><strong>Q:</strong> Can you explain the role of Zookeeper in a Kafka ecosystem?</p><ul><li><strong>A:</strong> Zookeeper plays a critical role in Kafka&rsquo;s architecture; it manages and coordinates Kafka brokers. It&rsquo;s responsible for leader election for partitions, managing configuration information, and maintaining a list of Kafka brokers and topics, as well as their status.</li></ul></li></ul><h3 id=flink>Flink</h3><ul><li><p><strong>Q:</strong> What advantages does Flink provide when dealing with stateful computations?</p><ul><li><strong>A:</strong> Flink offers robust state management and fault tolerance for stateful computations in streaming data. It maintains a consistent snapshot of all state throughout an applicationâ€™s execution, which can be recovered in case of a failure. Flink&rsquo;s checkpointing and savepoints feature are key for ensuring exactly-once processing semantics.</li></ul></li><li><p><strong>Q:</strong> How does Flink handle event time and out-of-order events?</p><ul><li><strong>A:</strong> Flink features an event time concept that deals with the time at which events actually occurred, as opposed to when they are processed by the system. With watermarks, which are special types of events that specify the progress of event time, Flink is capable of handling out-of-order events or late-arriving data.</li></ul></li></ul><h3 id=spark>Spark</h3><ul><li><p><strong>Q:</strong> What is the difference between RDDs, DataFrames, and Datasets in Spark?</p><ul><li><strong>A:</strong> RDD (Resilient Distributed Dataset) is the fundamental data structure in Spark - an immutable distributed collection of objects that can be processed in parallel. DataFrames are a collection of RDDs, but with a schema, which provides a higher level abstraction and optimization opportunities through Catalyst optimizer. Datasets are a type-safe version of DataFrames, allowing users to work with strongly-typed data collected as JVM objects.</li></ul></li><li><p><strong>Q:</strong> How does Spark achieve fault tolerance?</p><ul><li><strong>A:</strong> Spark achieves fault tolerance through its immutable data structure and lineage graph. In case of a partition failure, Spark can recompute the lost partition by replaying the transformations used to build the lineage of the RDD. This significantly reduces the need for data replication for fault tolerance purposes.</li></ul></li></ul><h3 id=hadoop>Hadoop</h3><ul><li><p><strong>Q:</strong> What are some of the core components of a Hadoop ecosystem?</p><ul><li><strong>A:</strong> The core of Hadoop consists of the storage layer, HDFS (Hadoop Distributed File System), for reliable storage of massive datasets, and YARN (Yet Another Resource Negotiator), for cluster resource management, and the MapReduce programming model for processing large datasets in parallel.</li></ul></li><li><p><strong>Q:</strong> How is data stored and processed in Hadoop?</p><ul><li><strong>A:</strong> In Hadoop, data is stored in HDFS across a distributed file system that spans the nodes in a Hadoop cluster. Data is processed using a MapReduce job where the data is first mapped, sorted/shuffled, and then reduced to produce an output - each of these steps can run in parallel across the cluster&rsquo;s nodes.</li></ul></li></ul><h3 id=iceberg>Iceberg</h3><ul><li><p><strong>Q:</strong> What is Apache Iceberg and how does it help with managing large data sets?</p><ul><li><strong>A:</strong> Apache Iceberg is a table format for large data sets that enables high-performance queries in distributed computing environments. It adds more structure and optimization to data storage, providing benefits like snapshot isolation, schema evolution, and efficient querying through hidden partitioning.</li></ul></li><li><p><strong>Q:</strong> Can Iceberg tables work with both batch and streaming data?</p><ul><li><strong>A:</strong> Yes, Iceberg tables are designed to support both batch and stream processing workloads seamlessly. They can be read and written to using traditional batch operations or incrementally using streaming workloads, thus, providing flexibility and ensuring up-to-date views of data.</li></ul></li></ul><h3 id=airflow>Airflow</h3><ul><li><p><strong>Q:</strong> What are the benefits of using Apache Airflow for workflow orchestration?</p><ul><li><strong>A:</strong> Apache Airflow provides a highly customizable platform for scheduling and coordinating complex data pipelines. It enables developers to define workflows as code, which allows for easy versioning, testing, and reusability. Its rich user interface aids in visualizing workflows, monitoring job progress, and diagnosing issues.</li></ul></li><li><p><strong>Q:</strong> How do you ensure that a task in Airflow is idempotent?</p><ul><li><strong>A:</strong> To make sure that a task in Airflow is idempotent - producing the same result regardless of how many times itâ€™s executed - you&rsquo;d structure your tasks so that the output depends solely on the inputs and the code at execution time. Also, using Airflow&rsquo;s extensive logging and external systems for state management can help ensure idempotency.</li></ul></li></ul><h3 id=presto>Presto</h3><ul><li><p><strong>Q:</strong> Why would you use Presto over other SQL-on-Hadoop engines?</p><ul><li><strong>A:</strong> Presto is designed for low-latency queries and is generally faster than other SQL-on-Hadoop engines due to its distributed architecture and query execution strategies. Unlike others, Presto does not use MapReduce; it processes data using an in-memory pipeline execution model which is significantly faster.</li></ul></li><li><p><strong>Q:</strong> How does Presto interact with different data sources, such as Iceberg or Kafka?</p><ul><li><strong>A:</strong> Presto has a connector architecture that allows it to interact with various data sources. For Iceberg, the Presto Iceberg connector provides support for reading from and writing to Iceberg tables. For Kafka, the Presto Kafka connector allows Presto to query Kafka topics directly as if they were tables. This flexibility makes it easy to combine and query data across different storage systems.</li></ul></li></ul><h2 id=design-choice-follow-ups>Design Choice Follow ups</h2><h3 id=kafka-1>Kafka</h3><ul><li><p><strong>Q:</strong> Why Kafka for tracking driver locations in real time and not other systems like RabbitMQ or ActiveMQ?</p><ul><li><p><strong>A:</strong> Kafka is built for high throughput and is capable of handling the vast volume of location updates generated by driversâ€”potentially millions of messages per second. Unlike RabbitMQ or ActiveMQ, Kafka excels at handling large streams of data efficiently, making it ideal for real-time analytics use cases. Also, Kafka&rsquo;s durable storage model allows us to reprocess historical data if needed.</p></li><li><p><strong>Pros:</strong>
Â Â Â Â - High throughput and scalability.
Â Â Â Â - Built-in partitioning and replication.
Â Â Â Â - Fault tolerance.</p></li><li><p><strong>Cons:</strong>
Â Â Â Â - Complexity in setup and management.
Â Â Â Â - Broker-centric storage with less queuing flexibility.</p></li><li><p><strong>Alternatives:</strong>
Â Â Â Â - RabbitMQ or Pulsar for simpler setups or additional messaging features but with potential scalability limitations.</p></li></ul></li></ul><h3 id=flink-1>Flink</h3><ul><li><p><strong>Q:</strong> Why use Apache Flink for real-time processing of driver locations?</p><ul><li><p><strong>A:</strong> Flink provides low-latency, accurate stream processing, which is critical for the driver location updates to reach customers in a timely manner. It&rsquo;s also good at handling stateful computations, like aggregating driver locations over windows of time. Apache Flink was chosen over alternatives like Apache Storm due to its greater throughput and ease of state management. However, we also considered Apache Kafka Streams for its tight integration with Kafka, but Flink offered more advanced windowing and state management features.</p></li><li><p><strong>Pros:</strong>
Â Â Â Â - High performance and low latency.
Â Â Â Â - Advanced state management.
Â Â Â Â - Effective event-time handling.</p></li><li><p><strong>Cons:</strong>
Â Â Â Â - Complexity for simpler stream processing needs.
Â Â Â Â - Possible overkill for less demanding tasks.</p></li><li><p><strong>Alternatives:</strong>
Â Â Â Â - Apache Storm for competent stream processing or Kafka Streams for Kafka-centric applications.</p></li></ul></li></ul><h3 id=spark-1>Spark</h3><ul><li><p><strong>Q:</strong> Why is Apache Spark preferred for batch processing and ML over other frameworks?</p><ul><li><p><strong>A:</strong> Spark provides a robust MLlib for machine learning, which we use to predict delivery times. It&rsquo;s optimized for iterative algorithms, such as those used in machine learning, and its in-memory computing capabilities speed up processing. This makes it highly effective for our driver location data analysis. An alternative could be Hadoop MapReduce, but it&rsquo;s a lot slower and less suited for complex analytics and ML tasks that Spark excels at.</p></li><li><p><strong>Pros:</strong>
Â Â Â Â - Fast performance with in-memory computing.
Â Â Â Â - Comprehensive MLlib for machine learning tasks.
Â Â Â Â - Unified APIs for diverse workloads.</p></li><li><p><strong>Cons:</strong>
Â Â Â Â - Resource-intensive, especially for memory.</p></li><li><p><strong>Alternatives:</strong>
Â Â Â Â - Hadoop MapReduce for cost-effective batch processing or cloud solutions like AWS EMR for managed services.</p></li></ul></li></ul><h3 id=hadoop-hdfs>Hadoop (HDFS)</h3><ul><li><p><strong>Q:</strong> Why prefer HDFS over cloud object storage like Amazon S3?</p><ul><li><p><strong>A:</strong> HDFS offers high throughput and is well-suited for the big data ecosystem, particularly with other Hadoop components. It integrates seamlessly with our data processing engines like Spark and our metadata management through Iceberg. While cloud object storage solutions are great for scalability and cost-effectiveness, HDFS gives us more control over our data locality and performance, which is important for our time-sensitive analytical workloads.</p></li><li><p><strong>Pros:</strong>
Â Â Â Â - Smooth integration with Hadoop-based tools.
Â Â Â Â - High throughput and performance.</p></li><li><p><strong>Cons:</strong>
Â Â Â Â - Complexity in management and operations.
Â Â Â Â - Less elasticity than cloud storage.</p></li><li><p><strong>Alternatives:</strong>
Â Â Â Â - Cloud solutions like Amazon S3 for scalability and simple operation.</p></li></ul></li></ul><h3 id=iceberg-1>Iceberg</h3><ul><li><p><strong>Q:</strong> How does Apache Iceberg improve large data table management and what are other options?</p><ul><li><p><strong>A:</strong> Iceberg offers reliable, scalable management of big data tables, addressing issues with older file formats like concurrency, versioning, and schema evolution. Iceberg integrates well with Spark and Flink, allowing us to easily manage table formats on HDFS. One alternative is Apache Hive, but it has limitations with metadata scaling which Iceberg has been designed to overcome.</p></li><li><p><strong>Pros:</strong>
Â Â Â Â - Efficient metadata management.
Â Â Â Â - Seamless schema evolution.
Â Â Â Â - Performance optimization through hidden partitioning.</p></li><li><p><strong>Cons:</strong>
Â Â Â Â - Less mature compared to formats like Parquet.</p></li><li><p><strong>Alternatives:</strong>
Â Â Â Â - Apache Hive for a traditional data warehouse approach, or Delta Lake for ACID transactions and building data pipelines.</p></li></ul></li></ul><h3 id=airflow-1>Airflow</h3><ul><li><p><strong>Q:</strong> Why Airflow over other workflow tools?</p><ul><li><p><strong>A:</strong> Airflow excels at defining, scheduling, and monitoring complex data pipelines. Its ability to code workflows as Directed Acyclic Graphs (DAGs) offers flexibility and transparency we need. Moreover, Airflow&rsquo;s user interface and community support are excellent. As an alternative, we considered Luigi and Apache NiFi, but Airflow&rsquo;s abilities to integrate with our data stack and intuitive UI made it the ideal choice for us.</p></li><li><p><strong>Pros:</strong>
Â Â Â Â - Flexibility with a Python-based programming model.
Â Â Â Â - Rich UI for management and monitoring.
Â Â Â Â - Broad integration with data processing tools.</p></li><li><p><strong>Cons:</strong>
Â Â Â Â - Potential resource intensity for simple needs.
Â Â Â Â - Learning curve for non-Python familiar developers.</p></li><li><p><strong>Alternatives:</strong>
Â Â Â Â - Luigi for simpler Python-centric workflows or Apache NiFi for a more visual-centric approach.</p></li></ul></li></ul><h3 id=presto-1>Presto</h3><ul><li><p><strong>Q:</strong> Why Presto for interactive querying against other technologies?</p><ul><li><p><strong>A:</strong> Presto&rsquo;s distributed in-memory architecture enables us to perform high-speed, ad-hoc queries directly on our data lake without data movement. It&rsquo;s flexible and supports a wide range of data sources, maintaining high performance for interactive analytics. We considered Apache Drill, but Presto&rsquo;s SQL compatibility and performance made it the better fit for our diverse data requirements.</p></li><li><p><strong>Pros:</strong>
Â Â Â Â - Fast querying over various data sources.
Â Â Â Â - Strong SQL support for diverse BI tools.</p></li><li><p><strong>Cons:</strong>
Â Â Â Â - Costly for large datasets due to in-memory processing.
Â Â Â Â - Suboptimal for extended, complex queries.</p></li><li><p><strong>Alternatives:</strong>
Â Â Â Â - Apache Drill for similar querying capabilities or managed cloud services like Amazon Athena for less operational involvement.</p></li></ul></li></ul></section><footer class=article-footer><section class=article-tags><a href=/tags/ubereats/>Ubereats</a>
<a href=/tags/big-data/>Big Data</a>
<a href=/tags/technical-interview/>Technical Interview</a>
<a href=/tags/system-design/>System Design</a>
<a href=/tags/kafka/>Kafka</a>
<a href=/tags/flink/>Flink</a>
<a href=/tags/iceberg/>Iceberg</a>
<a href=/tags/hadoop/>Hadoop</a>
<a href=/tags/presto/>Presto</a>
<a href=/tags/airflow/>Airflow</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/big-data-system-design-pinterest/><div class=article-image><img src=/p/big-data-system-design-pinterest/Pinterest-2-1024x500.78fcdcd06eed58b8045789ad949b7e83_huc282f49b8f48afaa5f37eb45efe62148_460836_250x150_fill_box_smart1_3.png width=250 height=150 loading=lazy alt="Featured image of post Big Data System Design Pinterest" data-hash="md5-ePzc0G7tWLgEV4mtlJt+gw=="></div><div class=article-details><h2 class=article-title>Big Data System Design Pinterest</h2></div></a></article><article class=has-image><a href=/p/system-design-interview-framework/><div class=article-image><img src=/p/system-design-interview-framework/banner.ea6d1516d5dd0f51df24f45918be64b9_hu6bdf848fc2e03cb76a7cc594088d1a18_89181_250x150_fill_q75_box_smart1.jpg width=250 height=150 loading=lazy alt="Featured image of post System Design Interview Framework" data-hash="md5-6m0VFtXdD1HfJPRZGL5kuQ=="></div><div class=article-details><h2 class=article-title>System Design Interview Framework</h2></div></a></article></div></div></aside><script src=https://giscus.app/client.js data-repo=xingfanxia/blog.xiax.xyz data-repo-id=R_kgDOLkaUkg data-category=Announcements data-category-id=DIC_kwDOLkaUks4CeNSA data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=en crossorigin=anonymous async></script><script>function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"light":"dark")}})()</script><footer class=site-footer><section class=copyright>&copy;
2024 A Cat Entertainer</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.24.2>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body><script type=module>
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true });
    </script></html>